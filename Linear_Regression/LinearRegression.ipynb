{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Learnings about Linear Regression\n",
    "\n",
    "**Disclaimer:** This notebook is a personal record of my understanding and explorations in linear regression. It should not be treated as definitive or authoritative, but rather a snapshot of my learning journey.\n",
    "\n",
    "### Overview\n",
    "- Linear regression is a method for modeling the relationship between one or more variables (features) and a expected output (target).\n",
    "- The goal is to find a linear function that best fits the data according to a chosen function or dataset, by minimizing the Mean Squared Error (MSE).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Overview\n",
    "\n",
    "Linear Regression considers the output as the result of a linear function of the input variables. The model is defined as:\n",
    "\n",
    "$$\n",
    "Y = w_0 + w_1 \\times X_1 + w_2 \\times X_2 + \\dots + w_n \\times X_n\n",
    "$$\n",
    "\n",
    "where:\n",
    "- **$w_0$** is the intercept,\n",
    "- **$w_1, w_2, \\dots, w_n$** are the coefficients corresponding to each feature $X_1, X_2, \\dots, X_n$.\n",
    "\n",
    "---\n",
    "\n",
    "### Matrix Representation of Input Data\n",
    "\n",
    "#### Input Matrix Without Intercept\n",
    "\n",
    "Assume you have \\(m\\) samples and \\(n\\) features. The input matrix \\(X\\) is organized as:\n",
    "\n",
    "$$\n",
    "X = \\begin{bmatrix}\n",
    "X_{11} & X_{12} & \\cdots & X_{1n} \\\\\n",
    "X_{21} & X_{22} & \\cdots & X_{2n} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "X_{m1} & X_{m2} & \\cdots & X_{mn} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Where $X_{ij}$ represents the _i_ th sample of the _j_th variable\\\\ \n",
    "\n",
    "If we use the dot product of \\(X\\) with a weight vector \\(W\\) where:\n",
    "\n",
    "$$\n",
    "W = \\begin{bmatrix}\n",
    "w_1 \\\\\n",
    "w_2 \\\\\n",
    "\\vdots \\\\\n",
    "w_n \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "the resulting prediction is:\n",
    "\n",
    "$$\n",
    "X \\cdot W = \\begin{bmatrix}\n",
    "w_1X_{11} + w_2X_{12} + \\dots + w_nX_{1n} \\\\\n",
    "w_1X_{21} + w_2X_{22} + \\dots + w_nX_{2n} \\\\\n",
    "\\vdots \\\\\n",
    "w_1X_{m1} + w_2X_{m2} + \\dots + w_nX_{mn} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Notice that this does not account for the intercept \\(w_0\\) and thus may be inaccurate.\n",
    "\n",
    "#### Accounting for the Intercept\n",
    "\n",
    "To include the intercept in our model, we augment the input matrix \\(X\\) by adding a column of  which is done in the above code by\\\\\n",
    "```sh\n",
    "    X_i = np.c_[np.ones((X.shape[0],1)),X]\n",
    "```\n",
    "\n",
    "where ```np.C_[a,b]``` concatenates two arrays _a_ and _b_ of similar height.\n",
    "\n",
    "This produces the new matrix \\(X_i\\):\n",
    "\n",
    "$$\n",
    "X_i = \\begin{bmatrix}\n",
    "1 & X_{11} & X_{12} & \\cdots & X_{1n} \\\\\n",
    "1 & X_{21} & X_{22} & \\cdots & X_{2n} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "1 & X_{m1} & X_{m2} & \\cdots & X_{mn} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The corresponding weight vector now includes \\(w_0\\):\n",
    "\n",
    "$$\n",
    "W_i = \\begin{bmatrix}\n",
    "w_0 \\\\\n",
    "w_1 \\\\\n",
    "\\vdots \\\\\n",
    "w_n \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The dot product becomes:\n",
    "\n",
    "$$\n",
    "X_i \\cdot W_i = \\begin{bmatrix}\n",
    "w_0 + w_1X_{11} + \\dots + w_nX_{1n} \\\\\n",
    "w_0 + w_1X_{21} + \\dots + w_nX_{2n} \\\\\n",
    "\\vdots \\\\\n",
    "w_0 + w_1X_{m1} + \\dots + w_nX_{mn} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This formulation is equivalent to the linear model:\n",
    "\n",
    "$$\n",
    "Y = w_0 + w_1 \\times X_1 + w_2 \\times X_2 + \\dots + w_n \\times X_n\n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y without w0: [11.5]\n",
      "Y with w0: [6.5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "w0 = -5\n",
    "w = np.array([0.5, 1, 10])  # w1, w2, w3\n",
    "\n",
    "X = np.ones((1, 3))\n",
    "\n",
    "Y_without_w0 = np.dot(X, w)\n",
    "X_with_intercept = np.c_[(np.ones((1, 1)), X)]\n",
    "\n",
    "W_full = np.array([w0, 0.5, 1, 10])  # w0, w1, w2, w3\n",
    "\n",
    "Y_with_w0 = np.dot(X_with_intercept, W_full)\n",
    "\n",
    "print(\"Y without w0:\", Y_without_w0)\n",
    "print(\"Y with w0:\", Y_with_w0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Without and With Intercept Term\n",
    "\n",
    "We assume the following weights:\n",
    "\n",
    "$$\n",
    "w_0 = -5, \\quad w_1 = 0.5, \\quad w_2 = 1, \\quad w_3 = 10\n",
    "$$\n",
    "\n",
    "#### Without Intercept (\\(w_0\\))\n",
    "\n",
    "We define \\( X \\) as:\n",
    "\n",
    "$$\n",
    "X = \\begin{bmatrix} 1 & 1 & 1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Performing the dot product with \\( w \\):\n",
    "\n",
    "$$\n",
    "Y_{\\text{without } w_0} = X \\cdot w = \\begin{bmatrix} 1 & 1 & 1 \\end{bmatrix} \\cdot \\begin{bmatrix} 0.5 \\\\ 1 \\\\ 10 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "Y_{\\text{without } w_0} = (1 \\times 0.5) + (1 \\times 1) + (1 \\times 10) = 11.5\n",
    "$$\n",
    "\n",
    "#### With Intercept (\\(w_0\\))\n",
    "\n",
    "To account for the intercept, we modify \\( X \\) by adding a column of ones:\n",
    "\n",
    "$$\n",
    "X_{\\text{with intercept}} = \\begin{bmatrix} 1 & 1 & 1 & 1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The new weight vector is:\n",
    "\n",
    "$$\n",
    "W_{\\text{full}} = \\begin{bmatrix} w_0 \\\\ w_1 \\\\ w_2 \\\\ w_3 \\end{bmatrix} = \\begin{bmatrix} -5 \\\\ 0.5 \\\\ 1 \\\\ 10 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Now, performing the dot product:\n",
    "\n",
    "$$\n",
    "Y_{\\text{with } w_0} = X_{\\text{with intercept}} \\cdot W_{\\text{full}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "Y_{\\text{with } w_0} = (1 \\times -5) + (1 \\times 0.5) + (1 \\times 1) + (1 \\times 10) = 6.5\n",
    "$$\n",
    "\n",
    "Thus, the results are:\n",
    "\n",
    "- **Without** $w_0$: $ 11.5 $\n",
    "- **With** $w_0$: $ 6.5 $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Gradient Descent in Linear Regression\n",
    "\n",
    "### What Are Gradients?\n",
    "\n",
    "Gradients tell us how much a function changes if we adjust its inputs. It is essentially the derivative of the function. In machine learning, gradients help us figure out how to update weights to reduce error. \n",
    "\n",
    "For example, if we have a function:\n",
    "\n",
    "$$\n",
    "f(x) = x^2\n",
    "$$\n",
    "\n",
    "The gradient (derivative) is:\n",
    "\n",
    "$$\n",
    "\\frac{df}{dx} = 2x\n",
    "$$\n",
    "At $x = 3$ the gradient is $6$ meaning the function is increasing. If we want to minimize it, we should move in the opposite direction.  \n",
    "\n",
    "---\n",
    "\n",
    "### Why Do We Use Gradients in Linear Regression?\n",
    "\n",
    "In linear regression, we predict \n",
    "\n",
    "$$\n",
    "Y_{\\text{pred}} = W \\cdot X\n",
    "$$\n",
    "\n",
    "We want to find the best $W$ (weights) that minimize the difference between $Y_{\\text{pred}}$ and actual $Y$. This difference is called the error:\n",
    "\n",
    "$$\n",
    "\\text{error} = Y_{\\text{pred}} - Y\n",
    "$$\n",
    "\n",
    "We measure how big the errors are using Mean Squared Error (MSE):\n",
    "\n",
    "$$\n",
    "MSE = \\frac{1}{m} \\sum (Y_{\\text{pred}} - Y)^2\n",
    "$$\n",
    "\n",
    "To reduce this error, we update $W$ using gradients.  \n",
    "\n",
    "---\n",
    "\n",
    "### How Do Gradients Help?\n",
    "\n",
    "The gradient of MSE with respect to weights tells us:\n",
    "\n",
    "- **Direction**: Which way to move $W$ to reduce error.\n",
    "- **Magnitude**: How big the update should be.\n",
    "\n",
    "The formula for the gradient is:\n",
    "\n",
    "$$\n",
    "\\frac{2}{m} X^T \\cdot (Y_{\\text{pred}} - Y)\n",
    "$$\n",
    "\n",
    "It tells us how much each weight contributes to the error.\\\n",
    "We shall derive this formula later.\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Rate and Weight Updates\n",
    "\n",
    "If we move too fast, we might miss the minimum. If we move too slow, learning takes forever. The **learning rate** $\\alpha$ controls this.  \n",
    "\n",
    "The weight update rule is:\n",
    "\n",
    "$$\n",
    "W_{\\text{new}} = W - \\alpha \\times \\text{gradient}\n",
    "$$\n",
    "\n",
    "If $\\alpha$ is too large, we might overshoot. If too small, learning is slow.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.learning_rate = kwargs.get(\"learning_rate\",0.01)\n",
    "        self.iterations = kwargs.get(\"iterations\",1000)\n",
    "        self.seed=12\n",
    "        self.W=None\n",
    "        \n",
    "        if len(args)>2:\n",
    "            X=args[0]\n",
    "            Y=args[1]\n",
    "            try:\n",
    "                self.fit(X,Y)\n",
    "            except Exception as e:\n",
    "                print(f\"ERROR: {e}\")\n",
    "                \n",
    "    def process_input(self, X, Y=None, fit_mode=True):# the use of the process function is explained later\n",
    "        X = np.asarray(X)\n",
    "        \n",
    "        if X.ndim == 0:\n",
    "            X = X.reshape(1, 1)\n",
    "\n",
    "        elif X.ndim == 1:\n",
    "            if fit_mode:\n",
    "                X = X.reshape(-1, 1)\n",
    "            else:\n",
    "                X = X.reshape(1, -1)\n",
    "        \n",
    "        if fit_mode:\n",
    "            if Y is None:\n",
    "                raise ValueError(\"Y cannot be None during fit.\")\n",
    "            Y = np.asarray(Y)\n",
    "            if Y.ndim == 0:\n",
    "                Y = np.array([Y])\n",
    "            elif Y.ndim == 2 and Y.shape[1] == 1:\n",
    "                Y = Y.flatten()\n",
    "        \n",
    "        return X, Y            \n",
    "    \n",
    "    def fit(self,X,Y):#explained above\n",
    "        X_i = np.c_[np.ones((X.shape[0],1)),X] #Adds intercept to X so that line is more accurate\n",
    "        np.random.seed(self.seed)#adds some consistency to the random weights chosen\n",
    "        self.W=np.random.randn(X_i.shape[1])#set random weights\n",
    "        \n",
    "        for iteration in range(self.iterations):\n",
    "            y_pred = X_i.dot(self.W)\n",
    "            errors = y_pred - Y\n",
    "            \n",
    "            gradients = (2/len(X_i)) * X_i.T.dot(errors)\n",
    "            \n",
    "            NEW_W = self.W - self.learning_rate * gradients\n",
    "            \n",
    "            if np.any(np.isnan(NEW_W)) or np.any(np.isinf(NEW_W)):#exit when error occurs in updating gradient either due to high alpha or division by zero\n",
    "                print(f\"NaN or Inf encountered at iteration {iteration}\")\n",
    "                break\n",
    "            self.W=NEW_W\n",
    "        return self\n",
    "    \n",
    "    def predict(self,X):\n",
    "        X=np.array(X)\n",
    "        if X.ndim==0:\n",
    "            X=np.array([[X]])\n",
    "        elif X.ndim==1:\n",
    "            X=X.reshape(-1,1)\n",
    "        try:\n",
    "            X = np.c_[np.ones((X.shape[0],1)),X]\n",
    "            return X.dot(self.W)\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deriving the Gradient for Mean Squared Error (MSE)\n",
    "\n",
    "To find the gradient, we differentiate the Mean Squared Error (MSE) with respect to each weight in the weight vector $W$.\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. Mean Squared Error (MSE) Definition\n",
    "\n",
    "The Mean Squared Error is:\n",
    "\n",
    "$$\n",
    "MSE = \\frac{1}{m} \\sum_{i=1}^{m} (Y_{\\text{pred}}^{(i)} - Y^{(i)})^2\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $m$ is the number of samples,\n",
    "- $Y_{\\text{pred}}^{(i)}$ is the predicted value for sample $i$,\n",
    "- $Y^{(i)}$ is the actual value.\n",
    "\n",
    "The prediction is given by:\n",
    "\n",
    "$$\n",
    "Y_{\\text{pred}} = XW\n",
    "$$\n",
    "\n",
    "where $X$ is the feature matrix and $W$ is the weight vector.\n",
    "\n",
    "The error term is:\n",
    "\n",
    "$$\n",
    "\\text{error} = Y_{\\text{pred}} - Y\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Differentiating MSE with Respect to Each Weight\n",
    "\n",
    "We differentiate $MSE$ with respect to each weight $w_j$.\n",
    "\n",
    "##### **For the first weight $w_1$:**\n",
    "\n",
    "$$\n",
    "\\frac{\\partial MSE}{\\partial w_1} = \\frac{1}{m} \\sum_{i=1}^{m} 2 (Y_{\\text{pred}}^{(i)} - Y^{(i)}) \\frac{\\partial Y_{\\text{pred}}^{(i)}}{\\partial w_1}\n",
    "$$\n",
    "\n",
    "Since:\n",
    "\n",
    "$$\n",
    "Y_{\\text{pred}}^{(i)} = w_1 X_1^{(i)} + w_2 X_2^{(i)} + \\dots + w_n X_n^{(i)}\n",
    "$$\n",
    "\n",
    "we have:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial Y_{\\text{pred}}^{(i)}}{\\partial w_1} = X_1^{(i)}\n",
    "$$\n",
    "\n",
    "Thus:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial MSE}{\\partial w_1} = \\frac{2}{m} \\sum_{i=1}^{m} (Y_{\\text{pred}}^{(i)} - Y^{(i)}) X_1^{(i)}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "##### **For the second weight $w_2$:**\n",
    "\n",
    "Similarly,\n",
    "\n",
    "$$\n",
    "\\frac{\\partial MSE}{\\partial w_2} = \\frac{2}{m} \\sum_{i=1}^{m} (Y_{\\text{pred}}^{(i)} - Y^{(i)}) X_2^{(i)}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "##### **For the third weight $w_3$:**\n",
    "\n",
    "$$\n",
    "\\frac{\\partial MSE}{\\partial w_3} = \\frac{2}{m} \\sum_{i=1}^{m} (Y_{\\text{pred}}^{(i)} - Y^{(i)}) X_3^{(i)}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Establishing the Pattern\n",
    "\n",
    "From the above, we see a general pattern:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial MSE}{\\partial w_j} = \\frac{2}{m} \\sum_{i=1}^{m} (Y_{\\text{pred}}^{(i)} - Y^{(i)}) X_j^{(i)}\n",
    "$$\n",
    "\n",
    "Writing this for all weights in matrix form:\n",
    "\n",
    "$$\n",
    "\\text{gradient} = \\frac{2}{m} X^T \\cdot (Y_{\\text{pred}} - Y)\n",
    "$$\n",
    "\n",
    "This shows that instead of computing each derivative separately, we can efficiently compute all gradients at once using matrix multiplication.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_input(self, X, Y=None, fit_mode=True):\n",
    "        X = np.asarray(X)\n",
    "        \n",
    "        if X.ndim == 0:\n",
    "            X = X.reshape(1, 1)\n",
    "\n",
    "        elif X.ndim == 1:\n",
    "            if fit_mode:\n",
    "                X = X.reshape(-1, 1)\n",
    "            else:\n",
    "                X = X.reshape(1, -1)\n",
    "        \n",
    "        if fit_mode:\n",
    "            if Y is None:\n",
    "                raise ValueError(\"Y cannot be None during fit.\")\n",
    "            Y = np.asarray(Y)\n",
    "            if Y.ndim == 0:\n",
    "                Y = np.array([Y])\n",
    "            elif Y.ndim == 2 and Y.shape[1] == 1:\n",
    "                Y = Y.flatten()\n",
    "        \n",
    "        return X, Y     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the `process_input` Function  \n",
    "\n",
    "#### Purpose of the Function  \n",
    "\n",
    "The `process_input` function is used to preprocess input data \\( X \\) and target values \\( Y \\) before feeding them into a machine learning model. It ensures that the input dimensions are correctly formatted based on whether the function is used for fitting (training) or making predictions.  \n",
    "\n",
    "---\n",
    "\n",
    "#### Handling Input \\( X \\)  \n",
    "\n",
    "The function first converts \\( X \\) into a NumPy array to ensure it is in the correct format:  \n",
    "\n",
    "$$\n",
    "X = \\text{np.asarray}(X)\n",
    "$$\n",
    "\n",
    "Then, it adjusts the shape of \\( X \\) based on its number of dimensions (`ndim`):  \n",
    "\n",
    "- **If \\( X \\) is a scalar (0-dimensional)**  \n",
    "  $$ X = X.reshape(1,1) $$  \n",
    "  This ensures even a single value is treated as a 2D array.  \n",
    "\n",
    "- **If \\( X \\) is a 1D array**  \n",
    "  - **During fitting (`fit_mode=True`)**  \n",
    "    $$ X = X.reshape(-1,1) $$  \n",
    "    This reshapes it into a column vector, which is common when training models.  \n",
    "  - **During prediction (`fit_mode=False`)**  \n",
    "    $$ X = X.reshape(1,-1) $$  \n",
    "    This ensures that a single feature vector is treated as a row vector, making it compatible with model inference.  \n",
    "\n",
    "---\n",
    "\n",
    "#### Handling Target \\( Y \\) (Only in Fit Mode)  \n",
    "\n",
    "When `fit_mode` is `True`, the function ensures \\( Y \\) is correctly formatted:  \n",
    "\n",
    "- **If \\( Y \\) is missing**, an error is raised:  \n",
    "  $$ \\text{raise ValueError(\"Y cannot be None during fit.\")} $$  \n",
    "\n",
    "- **Convert \\( Y \\) to a NumPy array**  \n",
    "  $$ Y = \\text{np.asarray}(Y) $$  \n",
    "\n",
    "- **If \\( Y \\) is a scalar (0D), convert it into a 1D array**  \n",
    "  $$ Y = \\text{np.array}([Y]) $$  \n",
    "\n",
    "- **If \\( Y \\) is a 2D column vector (\\( m \\times 1 \\)), flatten it to a 1D array**  \n",
    "  $$ Y = Y.flatten() $$  \n",
    "\n",
    "This ensures \\( Y \\) is always a 1D array, which is the expected format for most machine learning models.  \n",
    "\n",
    "---\n",
    "\n",
    "#### Final Output  \n",
    "\n",
    "The function returns the processed \\( X \\) and \\( Y \\), ensuring they are correctly shaped for training or prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Multivariable Linear Regression Implementation**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Importing **NumPy** for numerical operations and **Matplotlib** for visualization.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array([np.linspace(0,1,1000),\n",
    "            np.linspace(0,1,1000),\n",
    "            np.linspace(0,1,1000)]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creating a **3 variable feature matrix `X`**, where each **column** represents a different variable and each **row** is a different sample.  \n",
    "- `np.linspace(0,1,1000)` generates **1000 evenly spaced values** between `0` and `1` for each variable.  \n",
    "- `.T` transposes the array so that **each row is a sample** and **each column is a feature (X1, X2, X3)**.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Below is a test of predicting MultiVariable Linear Regression using\\n    the formula Y=10*X1+20*X2-5*X3+78\\n    Pls do note implementation of LinearRegression only accepts X in the\\n    form where each column is a different variable and row is a different sample\\n    \\n    for X=scalar it auto converts to [[X]]\\n    for X=1D array it converts into a column vecotr form\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Below is a test of predicting MultiVariable Linear Regression using\n",
    "    the formula Y=10*X1+20*X2-5*X3+78\n",
    "    Pls do note implementation of LinearRegression only accepts X in the\n",
    "    form where each column is a different variable and row is a different sample\n",
    "    \n",
    "    for X=scalar it auto converts to [[X]]\n",
    "    for X=1D array it converts into a column vecotr form\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Explanation of the model**:  \n",
    "  - The target variable `Y` is calculated using the equation:  \n",
    "    $$\n",
    "    Y = 10X_1 + 20X_2 - 5X_3 + 78\n",
    "    $$\n",
    "  - **`LinearRegression` expects `X` to be formatted** with columns as different variables and rows as samples.  \n",
    "  - If `X` is a **scalar**, it is **converted to** `[[X]]`.  \n",
    "  - If `X` is a **1D array**, it is **converted into a column vector**.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=(X-X.min())/(X.max()-X.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Feature scaling (Normalization)**:  \n",
    "  - Ensures that all values are within `[0,1]`, preventing large weights during training.  \n",
    "  - Formula:  \n",
    "    $$\n",
    "    X_{\\text{normalized}} = \\frac{X - X_{\\min}}{X_{\\max} - X_{\\min}}\n",
    "    $$\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LinearRegression(learning_rate=1e-3,iterations=int(1e5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Creating an instance of `LinearRegression`** with:  \n",
    "  - `learning_rate = 1e-3` (small step size for stable convergence).  \n",
    "  - `iterations = 10^5` (enough steps for optimization).  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=10*X[:,0]+20*X[:,1]-5*X[:,2]+78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Generating target values (`Y`)** using the given formula.  \n",
    "- `X[:,0]`, `X[:,1]`, and `X[:,2]` refer to the **three input features** (columns of `X`).  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LinearRegression at 0x1f3792cd400>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Training the model** by adjusting weights to minimize the error between predictions and actual `Y`.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre=np.array([[100,100,100],\n",
    "              [10,10,10]])#each column is a diff variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Creating a **test dataset** with two samples, each having three features (`X1, X2, X3`).  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2578.00000001  328.        ]\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(pre)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Predicting `Y` values** for the test samples using the trained model.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **Single-Variable Linear Regression (Plottable Case)**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.linspace(0,1,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Creating 100 points** equally spaced between `0` and `1` as the input feature.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=50.21*X-312"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Generating true `Y` values** using the equation:  \n",
    "  $$\n",
    "  Y = 50.21 X - 312\n",
    "  $$  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LinearRegression at 0x1f3792cd400>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Training the model** to learn the linear relationship between `X` and `Y`.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Adding random noise** with mean `0` and standard deviation `1` to simulate real-world data variability.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise=np.random.normal(0,1,size=X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Updating `Y` with noise** to introduce imperfections in the data.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=Y+noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Predicting `Y` values** using the trained model.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Plotting the noisy experimental data points** in **light gray**.  \n",
    "\n",
    "- **Plotting the predicted regression line** in **red**.  \n",
    "\n",
    "- **Displaying the graph** with labels and a legend.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.plot(X,y_pred,color=\"red\",label=\"predicted\")\n",
    "plt.scatter(X,Y,color=\"lightgray\",s=5,label=\"Experimental\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **Conclusion**\n",
    "- **Multivariable regression** was tested on a synthetic dataset with three input variables.  \n",
    "- **Single-variable regression** was visualized, showing that despite noise, the model still predicts well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
